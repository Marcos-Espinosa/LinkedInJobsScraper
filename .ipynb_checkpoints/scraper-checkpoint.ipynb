{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc8fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Necessary Imports for LinkedIn Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272a5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import logging\n",
    "from linkedin_jobs_scraper import LinkedinScraper\n",
    "from linkedin_jobs_scraper.events import Events,EventData,EventMetrics\n",
    "from linkedin_jobs_scraper.query import Query,QueryOptions,QueryFilters\n",
    "from linkedin_jobs_scraper.filters import RelevanceFilters, TimeFilters,TypeFilters,ExperienceLevelFilters, RemoteFilters\n",
    "\n",
    "\n",
    "# Necessary Imports for Extracting Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b34e6368",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6483a64e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logging.basicConfig(level = logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45607ac6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "job_postings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b166086c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def on_data(data: EventData):\n",
    "    job_postings.append([data.job_id,data.location,data.title,data.company,data.date,data.link,data.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a12f75",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def on_error(error):\n",
    "    print('[ON_ERROR]', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a736e6b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def on_end():\n",
    "    print('[ON_END]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5af11e8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chrome_driver_path = '/Users/marcosespinosa/Downloads/chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fba6a2a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:li:scraper:('Using strategy AnonymousStrategy',)\n",
      "WARNING:li:scraper:(\"AnonymousStrategy is no longer maintained and it won't probably work. It is recommended to use an authenticated session, see documentation at https://github.com/spinlud/py-linkedin-jobs-scraper#anonymous-vs-authenticated-session.\",)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "scraper = LinkedinScraper(\n",
    "    chrome_executable_path=chrome_driver_path,\n",
    "    chrome_options=None,\n",
    "    headless=True,\n",
    "    max_workers=1,\n",
    "    slow_mo=1.3,\n",
    "    page_load_timeout=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184b10e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scraper.on(Events.DATA, on_data)\n",
    "scraper.on(Events.ERROR, on_error)\n",
    "scraper.on(Events.END, on_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8068c67a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "queries = [\n",
    "    Query(\n",
    "        query='Python',\n",
    "        options=QueryOptions(\n",
    "            locations=['United States','Tampa,FL'],\n",
    "            apply_link = True,\n",
    "            limit = 27,\n",
    "            filters=QueryFilters(\n",
    "                relevance=RelevanceFilters.RECENT,\n",
    "                time=TimeFilters.MONTH,\n",
    "                type=[TypeFilters.FULL_TIME],\n",
    "                experience=None,\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "738c23b6",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:li:scraper:('Starting new query', \"Query(query=Python options=QueryOptions(limit=27 locations=['United States', 'Tampa,FL'] filters=QueryFilters(relevance=RelevanceFilters.RECENT time=TimeFilters.MONTH type=[<TypeFilters.FULL_TIME: 'F'>]) optimize=False apply_link=True))\")\n",
      "INFO:li:scraper:('Chrome debugger url', 'http://localhost:58859')\n",
      "INFO:li:scraper:('[Python][United States]', 'Opening https://www.linkedin.com/jobs/search?keywords=Python&location=United+States&sortBy=DD&f_TPR=r2592000&f_JT=F&start=0')\n",
      "INFO:li:scraper:('[Python][United States]', 'Trying first selectors set')\n",
      "INFO:li:scraper:('[Python][United States]', 'Trying second selectors set')\n",
      "INFO:li:scraper:('[Python][United States]', 'OK')\n",
      "INFO:li:scraper:('[Python][United States]', 'Starting pagination loop')\n",
      "INFO:li:scraper:('[Python][United States]', 'Found 24 jobs')\n",
      "INFO:li:scraper:('[Python][United States][1]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][2]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][3]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][4]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][5]', 'Processed')\n",
      "ERROR:li:scraper:('[Python][United States][6]', JavascriptException(\"javascript error: Cannot read properties of null (reading 'scrollIntoView')\\n  (Session info: headless chrome=105.0.5195.102)\", None, None), 'Traceback (most recent call last):\\n  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/linkedin_jobs_scraper/strategies/anonymous_strategy.py\", line 267, in run\\n    job_id, job_link, job_title, job_company, job_place, job_date = driver.execute_script(\\n  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\", line 634, in execute_script\\n    return self.execute(command, {\\n  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\\n    self.error_handler.check_response(response)\\n  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py\", line 242, in check_response\\n    raise exception_clas...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/linkedin_jobs_scraper/strategies/anonymous_strategy.py\", line 267, in run\n",
      "    job_id, job_link, job_title, job_company, job_place, job_date = driver.execute_script(\n",
      "  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\", line 634, in execute_script\n",
      "    return self.execute(command, {\n",
      "  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.JavascriptException: Message: javascript error: Cannot read properties of null (reading 'scrollIntoView')\n",
      "  (Session info: headless chrome=105.0.5195.102)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ON_ERROR] Message: javascript error: Cannot read properties of null (reading 'scrollIntoView')\n",
      "  (Session info: headless chrome=105.0.5195.102)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/linkedin_jobs_scraper/strategies/anonymous_strategy.py\", line 267, in run\n",
      "    job_id, job_link, job_title, job_company, job_place, job_date = driver.execute_script(\n",
      "  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\", line 634, in execute_script\n",
      "    return self.execute(command, {\n",
      "  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/Users/marcosespinosa/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.JavascriptException: Message: javascript error: Cannot read properties of null (reading 'scrollIntoView')\n",
      "  (Session info: headless chrome=105.0.5195.102)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:li:scraper:('[Python][United States][6]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][United States][7]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "INFO:li:scraper:('[Python][United States][7]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][8]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][9]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][10]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][United States][11]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][United States][11]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "INFO:li:scraper:('[Python][United States][11]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][12]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][13]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][United States][14]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][United States][14]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][United States][14]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "INFO:li:scraper:('[Python][United States][14]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][15]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][16]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][17]', 'Processed')\n",
      "INFO:li:scraper:('[Python][United States][17]', 'Checking for new jobs to load...')\n",
      "WARNING:li:scraper:('[Python][United States]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "INFO:li:scraper:('[Python][United States][17]', \"Couldn't find more jobs for the running query\")\n",
      "INFO:li:scraper:('Chrome debugger url', 'http://localhost:58886')\n",
      "INFO:li:scraper:('[Python][Tampa,FL]', 'Opening https://www.linkedin.com/jobs/search?keywords=Python&location=Tampa%2CFL&sortBy=DD&f_TPR=r2592000&f_JT=F&start=0')\n",
      "INFO:li:scraper:('[Python][Tampa,FL]', 'Trying first selectors set')\n",
      "INFO:li:scraper:('[Python][Tampa,FL]', 'Trying second selectors set')\n",
      "INFO:li:scraper:('[Python][Tampa,FL]', 'OK')\n",
      "INFO:li:scraper:('[Python][Tampa,FL]', 'Starting pagination loop')\n",
      "INFO:li:scraper:('[Python][Tampa,FL]', 'Found 25 jobs')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][1]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][2]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][3]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][4]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][5]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][6]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][7]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][Tampa,FL][8]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "INFO:li:scraper:('[Python][Tampa,FL][8]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][9]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][10]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][11]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][12]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][Tampa,FL][13]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][13]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][14]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][15]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][16]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][17]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][Tampa,FL][18]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][Tampa,FL][18]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "INFO:li:scraper:('[Python][Tampa,FL][18]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][Tampa,FL][19]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "INFO:li:scraper:('[Python][Tampa,FL][19]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][20]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][21]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][Tampa,FL][22]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "INFO:li:scraper:('[Python][Tampa,FL][22]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][23]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][24]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][Tampa,FL][25]', 'Timeout on loading job details')\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:li:scraper:('[Python][Tampa,FL][25]', 'Processed')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "WARNING:li:scraper:('[Python][Tampa,FL]', '[429] Too many requests', 'You should probably increase scraper \"slow_mo\" value or reduce concurrency')\n",
      "ERROR:li:scraper:('[Python][Tampa,FL][26]', 'Timeout on loading job details')\n",
      "NoneType: None\n",
      "INFO:li:scraper:('[Python][Tampa,FL][26]', 'Processed')\n",
      "INFO:li:scraper:('[Python][Tampa,FL][27]', 'Processed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ON_END]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "scraper.run(queries)\n",
    "\n",
    "\n",
    "# In[27]: Create Pandas Dataframe from ON_DATE results\n",
    "\n",
    "\n",
    "df = pd.DataFrame(job_postings,columns=['Job_ID','Location','Title','Company','Date','Link','Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec03286e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3253034666</td>\n",
       "      <td>United States</td>\n",
       "      <td>Python Developer</td>\n",
       "      <td>Supertek, LLC</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/python-deve...</td>\n",
       "      <td>Python Engineer\\nJob Description\\n\\nJob Type: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3253051563</td>\n",
       "      <td>United States</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Alkymi</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>At Alkymi, we’re on a mission to supercharge h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3245362833</td>\n",
       "      <td>United States</td>\n",
       "      <td>Python Developer</td>\n",
       "      <td>Polymer SaaS DLP</td>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/python-deve...</td>\n",
       "      <td>About Polymer\\n\\n\\n\\n\\nPolymer is a No-Code Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3254820222</td>\n",
       "      <td>United States</td>\n",
       "      <td>Software Engineer, University Graduate (Busine...</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>Responsibilities\\n\\nTikTok is the leading dest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3242829720</td>\n",
       "      <td>United States</td>\n",
       "      <td>Python Backend Engineer</td>\n",
       "      <td>Geomagical Labs</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/python-back...</td>\n",
       "      <td>Geomagical Labs is crafting 3D AI experiences ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Job_ID       Location  \\\n",
       "0  3253034666  United States   \n",
       "1  3253051563  United States   \n",
       "2  3245362833  United States   \n",
       "3  3254820222  United States   \n",
       "4  3242829720  United States   \n",
       "\n",
       "                                               Title           Company  \\\n",
       "0                                   Python Developer     Supertek, LLC   \n",
       "1                                     Data Scientist            Alkymi   \n",
       "2                                   Python Developer  Polymer SaaS DLP   \n",
       "3  Software Engineer, University Graduate (Busine...            TikTok   \n",
       "4                            Python Backend Engineer   Geomagical Labs   \n",
       "\n",
       "         Date                                               Link  \\\n",
       "0  2022-09-05  https://www.linkedin.com/jobs/view/python-deve...   \n",
       "1  2022-09-05  https://www.linkedin.com/jobs/view/data-scient...   \n",
       "2  2022-08-30  https://www.linkedin.com/jobs/view/python-deve...   \n",
       "3  2022-09-05  https://www.linkedin.com/jobs/view/software-en...   \n",
       "4  2022-08-29  https://www.linkedin.com/jobs/view/python-back...   \n",
       "\n",
       "                                         Description  \n",
       "0  Python Engineer\\nJob Description\\n\\nJob Type: ...  \n",
       "1  At Alkymi, we’re on a mission to supercharge h...  \n",
       "2  About Polymer\\n\\n\\n\\n\\nPolymer is a No-Code Da...  \n",
       "3  Responsibilities\\n\\nTikTok is the leading dest...  \n",
       "4  Geomagical Labs is crafting 3D AI experiences ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8179906",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcount ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dc6b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['and','to','the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61fd2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df['Description']:\n",
    "    for word in text.lower().split():\n",
    "        word = word.replace(\".\",\"\")\n",
    "        word = word.replace(\",\",\"\")\n",
    "        word = word.replace(\":\",\"\")\n",
    "        word = word.replace(\"\\\"\",\"\")\n",
    "        word = word.replace(\"!\",\"\")\n",
    "        word = word.replace(\"â€œ\",\"\")\n",
    "        word = word.replace(\"â€˜\",\"\")\n",
    "        word = word.replace(\"*\",\"\")\n",
    "        if word not in stopwords:\n",
    "            if word not in wordcount:\n",
    "                wordcount[word] = 1\n",
    "            else:\n",
    "                wordcount[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1c08927",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = collections.Counter(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19e11236",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = word_counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4004815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_df = pd.DataFrame(lst, columns = ['Word','Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "204508a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>benefits</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>join</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>able</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>can</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>technologies</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Count\n",
       "0            and    884\n",
       "1             of    680\n",
       "2             in    582\n",
       "3              a    528\n",
       "4             to    516\n",
       "..           ...    ...\n",
       "95      benefits     48\n",
       "96          join     48\n",
       "97          able     48\n",
       "98           can     48\n",
       "99  technologies     48\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e20d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
